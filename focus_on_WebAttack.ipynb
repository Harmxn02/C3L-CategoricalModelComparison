{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Model Comparison\n",
    "\n",
    "**only_DOS.ipynb**\n",
    "\n",
    "In this notebook we train a model focussing on WebAttack attack data, and export the model for use in the **categorical_model_comparison.ipynb** notebook.\n",
    "\n",
    "We will use a CNN-GAN model described in this study: <https://www.jait.us/articles/2024/JAIT-V15N7-886.pdf>\n",
    "\n",
    "Our dataset is the CIC-IDS-2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook = \"focus_on_WebAttack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./data/concat.csv\")\n",
    "\n",
    "# Trim whitespace from column names\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow Bytes/s                   1358\n",
       "Flow Duration                     0\n",
       "Destination Port                  0\n",
       "Total Backward Packets            0\n",
       "Total Length of Fwd Packets       0\n",
       "                               ... \n",
       "Idle Mean                         0\n",
       "Idle Std                          0\n",
       "Idle Max                          0\n",
       "Idle Min                          0\n",
       "Label                             0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"Flow Bytes/s\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf. values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Destination Port               0\n",
       "Flow Duration                  0\n",
       "Total Fwd Packets              0\n",
       "Total Backward Packets         0\n",
       "Total Length of Fwd Packets    0\n",
       "                              ..\n",
       "Idle Mean                      0\n",
       "Idle Std                       0\n",
       "Idle Max                       0\n",
       "Idle Min                       0\n",
       "Label                          0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=\"number\").columns\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map labels to multi-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**important**: Here we drop all the benign rows, so we are left with only the attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Others                        554376\n",
       "Web Attack � Brute Force        1507\n",
       "Web Attack � XSS                 652\n",
       "Web Attack � Sql Injection        21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"Label\"] != \"BENIGN\"]\n",
    "\n",
    "# Keep these labels as is: Web Attack � Brute Force, Web Attack � XSS, Web Attack � Sql Injection\n",
    "# Combine these labels into \"Others\"\n",
    "\n",
    "df[\"Label\"] = df[\"Label\"].replace([\"DoS Hulk\", \"PortScan\", \"DDoS\", \"DoS GoldenEye\", \"FTP-Patator\", \"SSH-Patator\", \"DoS slowloris\", \"DoS Slowhttptest\", \"Bot\", \"Infiltration\", \"Heartbleed\"], \"Others\")\n",
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_mapping = {\n",
    "\t\"Others\": 0,\n",
    "\t\"Web Attack � Brute Force\": 1,\n",
    "\t\"Web Attack � XSS\": 2,\n",
    "\t\"Web Attack � Sql Injection\": 3,\n",
    "}\n",
    "\n",
    "df[\"Label\"] = df[\"Label\"].map(attack_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    554376\n",
       "1      1507\n",
       "2       652\n",
       "3        21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Label\"])\n",
    "y = df[\"Label\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample all values below 10.000\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy={\n",
    "\t0: 1000,\n",
    "\t1: 1000,\n",
    "}, random_state=28)\n",
    "\n",
    "rus_testset = RandomUnderSampler(sampling_strategy={\n",
    "\t0: 200,\n",
    "\t1: 200,\n",
    "}, random_state=28)\n",
    "\n",
    "X_train_balanced, y_train_balanced = rus.fit_resample(X_train, y_train)\n",
    "X_test_balanced, y_test_balanced = rus_testset.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample all values below 10.000\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy={\n",
    "\t2: 1000,\n",
    "\t3: 1000,\n",
    "}, random_state=28)\n",
    "\n",
    "ros_testset = RandomOverSampler(sampling_strategy={\n",
    "\t2: 200,\n",
    "\t3: 200,\n",
    "}, random_state=28)\n",
    "\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train_balanced, y_train_balanced)\n",
    "X_test_balanced, y_test_balanced = ros_testset.fit_resample(X_test_balanced, y_test_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: Counter({0: 443475, 1: 1223, 2: 528, 3: 18})\n",
      "Class distribution after SMOTE: Counter({0: 1000, 1: 1000, 2: 1000, 3: 1000})\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution after SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "print(f\"Class distribution before SMOTE: {Counter(y_train)}\")\n",
    "print(f\"Class distribution after SMOTE: {Counter(y_train_balanced)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CNN Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Define CNN Feature Extractor\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_size, num_filters=32):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=num_filters, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear((input_size // 2) * num_filters, 64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generator-Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Define Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hybrid Model\n",
    "class HybridCNNGAN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, noise_dim=32):\n",
    "        super(HybridCNNGAN, self).__init__()\n",
    "        self.feature_extractor = CNNFeatureExtractor(input_size)\n",
    "        self.classifier = nn.Linear(64, output_size)\n",
    "        self.generator = Generator(noise_dim, input_size)\n",
    "        self.discriminator = Discriminator(input_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Model Summary\n",
      "------------------------------\n",
      "HybridCNNGAN(\n",
      "  (feature_extractor): CNNFeatureExtractor(\n",
      "    (conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (relu): ReLU()\n",
      "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=1248, out_features=64, bias=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (generator): Generator(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=78, bias=True)\n",
      "      (3): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (discriminator): Discriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=78, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "------------------------------\n",
      "Device: cuda\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_size = X_train_balanced.shape[1]\n",
    "output_size = len(attack_mapping)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridCNNGAN(input_size, output_size).to(device)\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(\"Model Summary\")\n",
    "print(\"-\"*30)\n",
    "print(model)\n",
    "print(\"-\"*30)\n",
    "print(\"Device:\", device)\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000] - Loss: 1.1408 - Accuracy: 0.4627\n",
      "Epoch [2/10000] - Loss: 0.8050 - Accuracy: 0.6555\n",
      "Epoch [3/10000] - Loss: 0.6228 - Accuracy: 0.6993\n",
      "Epoch [4/10000] - Loss: 0.5528 - Accuracy: 0.7268\n",
      "Epoch [5/10000] - Loss: 0.5209 - Accuracy: 0.7342\n",
      "Epoch [6/10000] - Loss: 0.5058 - Accuracy: 0.7310\n",
      "Epoch [7/10000] - Loss: 0.4979 - Accuracy: 0.7415\n",
      "Epoch [8/10000] - Loss: 0.4889 - Accuracy: 0.7372\n",
      "Epoch [9/10000] - Loss: 0.4816 - Accuracy: 0.7395\n",
      "Epoch [11/10000] - Loss: 0.4802 - Accuracy: 0.7332\n",
      "Epoch [12/10000] - Loss: 0.4729 - Accuracy: 0.7370\n",
      "Epoch [13/10000] - Loss: 0.4723 - Accuracy: 0.7462\n",
      "Epoch [15/10000] - Loss: 0.4650 - Accuracy: 0.7468\n",
      "Epoch [17/10000] - Loss: 0.4647 - Accuracy: 0.7380\n",
      "Epoch [18/10000] - Loss: 0.4625 - Accuracy: 0.7352\n",
      "Epoch [20/10000] - Loss: 0.4603 - Accuracy: 0.7470\n",
      "Epoch [21/10000] - Loss: 0.4561 - Accuracy: 0.7515\n",
      "Epoch [22/10000] - Loss: 0.4531 - Accuracy: 0.7520\n",
      "Epoch [25/10000] - Loss: 0.4475 - Accuracy: 0.7485\n",
      "Epoch [26/10000] - Loss: 0.4471 - Accuracy: 0.7525\n",
      "Epoch [27/10000] - Loss: 0.4449 - Accuracy: 0.7530\n",
      "Epoch [29/10000] - Loss: 0.4401 - Accuracy: 0.7472\n",
      "Epoch [30/10000] - Loss: 0.4381 - Accuracy: 0.7605\n",
      "Epoch [32/10000] - Loss: 0.4378 - Accuracy: 0.7502\n",
      "Epoch [37/10000] - Loss: 0.4330 - Accuracy: 0.7570\n",
      "Epoch [39/10000] - Loss: 0.4313 - Accuracy: 0.7480\n",
      "Epoch [40/10000] - Loss: 0.4304 - Accuracy: 0.7575\n",
      "Epoch [41/10000] - Loss: 0.4302 - Accuracy: 0.7608\n",
      "Epoch [42/10000] - Loss: 0.4302 - Accuracy: 0.7625\n",
      "Epoch [43/10000] - Loss: 0.4292 - Accuracy: 0.7595\n",
      "Epoch [44/10000] - Loss: 0.4274 - Accuracy: 0.7512\n",
      "Epoch [46/10000] - Loss: 0.4265 - Accuracy: 0.7602\n",
      "Epoch [47/10000] - Loss: 0.4209 - Accuracy: 0.7660\n",
      "Epoch [52/10000] - Loss: 0.4196 - Accuracy: 0.7572\n",
      "Epoch [54/10000] - Loss: 0.4191 - Accuracy: 0.7695\n",
      "Epoch [55/10000] - Loss: 0.4168 - Accuracy: 0.7610\n",
      "Epoch [57/10000] - Loss: 0.4123 - Accuracy: 0.7715\n",
      "Epoch [60/10000] - Loss: 0.4119 - Accuracy: 0.7715\n",
      "Epoch [63/10000] - Loss: 0.4090 - Accuracy: 0.7700\n",
      "Epoch [64/10000] - Loss: 0.4081 - Accuracy: 0.7728\n",
      "Epoch [65/10000] - Loss: 0.4069 - Accuracy: 0.7678\n",
      "Epoch [66/10000] - Loss: 0.4067 - Accuracy: 0.7720\n",
      "Epoch [70/10000] - Loss: 0.4048 - Accuracy: 0.7798\n",
      "Epoch [72/10000] - Loss: 0.4015 - Accuracy: 0.7835\n",
      "Epoch [79/10000] - Loss: 0.3977 - Accuracy: 0.7798\n",
      "Epoch [83/10000] - Loss: 0.3957 - Accuracy: 0.7845\n",
      "Epoch [87/10000] - Loss: 0.3955 - Accuracy: 0.7850\n",
      "Epoch [91/10000] - Loss: 0.3948 - Accuracy: 0.7845\n",
      "Epoch [92/10000] - Loss: 0.3923 - Accuracy: 0.7890\n",
      "Epoch [95/10000] - Loss: 0.3907 - Accuracy: 0.7877\n",
      "Epoch [101/10000] - Loss: 0.3875 - Accuracy: 0.7957\n",
      "Epoch [102/10000] - Loss: 0.3872 - Accuracy: 0.8000\n",
      "Epoch [111/10000] - Loss: 0.3864 - Accuracy: 0.7863\n",
      "Epoch [113/10000] - Loss: 0.3860 - Accuracy: 0.7877\n",
      "Epoch [123/10000] - Loss: 0.3853 - Accuracy: 0.7933\n",
      "Epoch [125/10000] - Loss: 0.3835 - Accuracy: 0.7927\n",
      "Epoch [132/10000] - Loss: 0.3810 - Accuracy: 0.7980\n",
      "Epoch [137/10000] - Loss: 0.3810 - Accuracy: 0.8033\n",
      "Epoch [148/10000] - Loss: 0.3799 - Accuracy: 0.7973\n",
      "Epoch [153/10000] - Loss: 0.3784 - Accuracy: 0.8073\n",
      "Epoch [164/10000] - Loss: 0.3769 - Accuracy: 0.8015\n",
      "Epoch [197/10000] - Loss: 0.3733 - Accuracy: 0.8025\n",
      "Epoch [232/10000] - Loss: 0.3730 - Accuracy: 0.7945\n",
      "Epoch [252/10000] - Loss: 0.3722 - Accuracy: 0.8037\n",
      "Epoch [282/10000] - Loss: 0.3707 - Accuracy: 0.8007\n",
      "Epoch [293/10000] - Loss: 0.3688 - Accuracy: 0.8023\n",
      "Epoch [338/10000] - Loss: 0.3676 - Accuracy: 0.8123\n",
      "Epoch [370/10000] - Loss: 0.3662 - Accuracy: 0.8080\n",
      "Epoch [475/10000] - Loss: 0.3660 - Accuracy: 0.8063\n",
      "Epoch [484/10000] - Loss: 0.3651 - Accuracy: 0.8120\n",
      "Epoch [511/10000] - Loss: 0.3641 - Accuracy: 0.8090\n",
      "Epoch [550/10000] - Loss: 0.3640 - Accuracy: 0.8043\n",
      "Epoch [600/10000] - Loss: 0.3628 - Accuracy: 0.8053\n",
      "Epoch [682/10000] - Loss: 0.3628 - Accuracy: 0.8097\n",
      "Epoch [684/10000] - Loss: 0.3626 - Accuracy: 0.8043\n",
      "Epoch [717/10000] - Loss: 0.3614 - Accuracy: 0.8097\n",
      "Epoch [763/10000] - Loss: 0.3610 - Accuracy: 0.8075\n",
      "Epoch [767/10000] - Loss: 0.3607 - Accuracy: 0.8053\n",
      "Epoch [836/10000] - Loss: 0.3601 - Accuracy: 0.8133\n",
      "Epoch [919/10000] - Loss: 0.3600 - Accuracy: 0.8087\n",
      "Epoch [938/10000] - Loss: 0.3599 - Accuracy: 0.8055\n",
      "Epoch [943/10000] - Loss: 0.3593 - Accuracy: 0.8033\n",
      "Epoch [972/10000] - Loss: 0.3591 - Accuracy: 0.8110\n",
      "Epoch [1046/10000] - Loss: 0.3590 - Accuracy: 0.8030\n",
      "Epoch [1048/10000] - Loss: 0.3584 - Accuracy: 0.8095\n",
      "Epoch [1065/10000] - Loss: 0.3583 - Accuracy: 0.8093\n",
      "Epoch [1111/10000] - Loss: 0.3579 - Accuracy: 0.8087\n",
      "Epoch [1144/10000] - Loss: 0.3578 - Accuracy: 0.8037\n",
      "Epoch [1162/10000] - Loss: 0.3578 - Accuracy: 0.8133\n",
      "Epoch [1164/10000] - Loss: 0.3577 - Accuracy: 0.8043\n",
      "Epoch [1243/10000] - Loss: 0.3573 - Accuracy: 0.8120\n",
      "Epoch [1253/10000] - Loss: 0.3568 - Accuracy: 0.8105\n",
      "Epoch [1335/10000] - Loss: 0.3560 - Accuracy: 0.8187\n",
      "Epoch [1580/10000] - Loss: 0.3557 - Accuracy: 0.8160\n",
      "Epoch [1613/10000] - Loss: 0.3549 - Accuracy: 0.8013\n",
      "Epoch [1746/10000] - Loss: 0.3548 - Accuracy: 0.8110\n",
      "Epoch [1768/10000] - Loss: 0.3548 - Accuracy: 0.8103\n",
      "Epoch [1810/10000] - Loss: 0.3543 - Accuracy: 0.8093\n",
      "Epoch [1858/10000] - Loss: 0.3541 - Accuracy: 0.8103\n",
      "Epoch [1873/10000] - Loss: 0.3533 - Accuracy: 0.8090\n",
      "Epoch [1905/10000] - Loss: 0.3533 - Accuracy: 0.8167\n",
      "Epoch [1906/10000] - Loss: 0.3532 - Accuracy: 0.8193\n",
      "Epoch [1933/10000] - Loss: 0.3532 - Accuracy: 0.8167\n",
      "Epoch [1955/10000] - Loss: 0.3531 - Accuracy: 0.8133\n",
      "Epoch [2027/10000] - Loss: 0.3530 - Accuracy: 0.8145\n",
      "Epoch [2050/10000] - Loss: 0.3519 - Accuracy: 0.8175\n",
      "Epoch [2164/10000] - Loss: 0.3513 - Accuracy: 0.8203\n",
      "Epoch [2207/10000] - Loss: 0.3509 - Accuracy: 0.8147\n",
      "Epoch [2294/10000] - Loss: 0.3505 - Accuracy: 0.8157\n",
      "Epoch [2364/10000] - Loss: 0.3489 - Accuracy: 0.8173\n",
      "Epoch [2528/10000] - Loss: 0.3489 - Accuracy: 0.8170\n",
      "Epoch [2553/10000] - Loss: 0.3488 - Accuracy: 0.8160\n",
      "Epoch [2559/10000] - Loss: 0.3486 - Accuracy: 0.8205\n",
      "Epoch [2668/10000] - Loss: 0.3483 - Accuracy: 0.8135\n",
      "Epoch [2716/10000] - Loss: 0.3477 - Accuracy: 0.8160\n",
      "Epoch [2941/10000] - Loss: 0.3474 - Accuracy: 0.8165\n",
      "Epoch [2965/10000] - Loss: 0.3470 - Accuracy: 0.8170\n",
      "Epoch [3123/10000] - Loss: 0.3470 - Accuracy: 0.8225\n",
      "Epoch [3210/10000] - Loss: 0.3457 - Accuracy: 0.8185\n",
      "Epoch [3389/10000] - Loss: 0.3456 - Accuracy: 0.8195\n",
      "Epoch [3456/10000] - Loss: 0.3454 - Accuracy: 0.8193\n",
      "Epoch [3487/10000] - Loss: 0.3449 - Accuracy: 0.8177\n",
      "Epoch [3566/10000] - Loss: 0.3446 - Accuracy: 0.8180\n",
      "Epoch [3860/10000] - Loss: 0.3443 - Accuracy: 0.8210\n",
      "Epoch [3918/10000] - Loss: 0.3438 - Accuracy: 0.8220\n",
      "Epoch [4103/10000] - Loss: 0.3435 - Accuracy: 0.8203\n",
      "Epoch [4150/10000] - Loss: 0.3432 - Accuracy: 0.8203\n",
      "Epoch [4163/10000] - Loss: 0.3431 - Accuracy: 0.8223\n",
      "Epoch [4213/10000] - Loss: 0.3430 - Accuracy: 0.8195\n",
      "Epoch [4221/10000] - Loss: 0.3430 - Accuracy: 0.8190\n",
      "Epoch [4225/10000] - Loss: 0.3428 - Accuracy: 0.8217\n",
      "Epoch [4273/10000] - Loss: 0.3427 - Accuracy: 0.8180\n",
      "Epoch [4380/10000] - Loss: 0.3427 - Accuracy: 0.8230\n",
      "Epoch [4416/10000] - Loss: 0.3421 - Accuracy: 0.8210\n",
      "Epoch [4513/10000] - Loss: 0.3418 - Accuracy: 0.8223\n",
      "Epoch [4565/10000] - Loss: 0.3417 - Accuracy: 0.8183\n",
      "Epoch [4654/10000] - Loss: 0.3415 - Accuracy: 0.8203\n",
      "Epoch [4661/10000] - Loss: 0.3414 - Accuracy: 0.8193\n",
      "Epoch [4662/10000] - Loss: 0.3412 - Accuracy: 0.8170\n",
      "Epoch [4760/10000] - Loss: 0.3408 - Accuracy: 0.8225\n",
      "Epoch [4814/10000] - Loss: 0.3388 - Accuracy: 0.8227\n",
      "Epoch [5364/10000] - Loss: 0.3380 - Accuracy: 0.8213\n",
      "Epoch [5512/10000] - Loss: 0.3371 - Accuracy: 0.8197\n",
      "Epoch [5823/10000] - Loss: 0.3367 - Accuracy: 0.8237\n",
      "Epoch [5958/10000] - Loss: 0.3364 - Accuracy: 0.8185\n",
      "Epoch [5993/10000] - Loss: 0.3346 - Accuracy: 0.8183\n",
      "Epoch [6542/10000] - Loss: 0.3337 - Accuracy: 0.8195\n",
      "Epoch [6620/10000] - Loss: 0.3322 - Accuracy: 0.8213\n",
      "Epoch [6859/10000] - Loss: 0.3316 - Accuracy: 0.8165\n",
      "Epoch [7099/10000] - Loss: 0.3306 - Accuracy: 0.8253\n",
      "Epoch [7264/10000] - Loss: 0.3301 - Accuracy: 0.8225\n",
      "Epoch [7407/10000] - Loss: 0.3296 - Accuracy: 0.8247\n",
      "Epoch [7444/10000] - Loss: 0.3293 - Accuracy: 0.8207\n",
      "Epoch [7480/10000] - Loss: 0.3282 - Accuracy: 0.8203\n",
      "Epoch [7815/10000] - Loss: 0.3281 - Accuracy: 0.8235\n",
      "Epoch [7872/10000] - Loss: 0.3268 - Accuracy: 0.8233\n",
      "Epoch [8322/10000] - Loss: 0.3263 - Accuracy: 0.8193\n",
      "Epoch [8323/10000] - Loss: 0.3263 - Accuracy: 0.8240\n",
      "Epoch [8471/10000] - Loss: 0.3256 - Accuracy: 0.8217\n",
      "Epoch [8496/10000] - Loss: 0.3256 - Accuracy: 0.8223\n",
      "Epoch [8561/10000] - Loss: 0.3255 - Accuracy: 0.8263\n",
      "Epoch [8600/10000] - Loss: 0.3246 - Accuracy: 0.8235\n",
      "Epoch [8949/10000] - Loss: 0.3243 - Accuracy: 0.8217\n",
      "Epoch [9465/10000] - Loss: 0.3243 - Accuracy: 0.8247\n",
      "Epoch [9473/10000] - Loss: 0.3239 - Accuracy: 0.8253\n",
      "Epoch [9482/10000] - Loss: 0.3232 - Accuracy: 0.8215\n",
      "Epoch [10000/10000] - Loss: 0.3253 - Accuracy: 0.8223\r"
     ]
    }
   ],
   "source": [
    "# Early stopping setup\n",
    "early_stopping_patience = 10000\n",
    "best_loss = float(\"inf\")\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Training Setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_balanced.values, dtype=torch.float32).to(device),\n",
    "                              torch.tensor(y_train_balanced.values, dtype=torch.long).to(device))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "\tmodel.train()\n",
    "\ttotal_loss, correct, total = 0, 0, 0\n",
    "\tfor i, (data, labels) in enumerate(train_loader):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = model(data)\n",
    "\t\tloss = criterion(outputs, labels)\n",
    "\t\t\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\ttotal_loss += loss.item()\n",
    "\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\ttotal += labels.size(0)\n",
    "\t\t\n",
    "\t\tcorrect += (predicted == labels).sum().item()\n",
    "\t\tprogress = (i + 1) / len(train_loader) * 100\n",
    "\t\t\n",
    "\t\t# print(f'\\rEpoch [{epoch+1}/{num_epochs}] - Progress: {progress:.1f}%', end='')\n",
    "\n",
    "\tepoch_loss = total_loss / len(train_loader)\n",
    "\tepoch_accuracy = correct / total\n",
    "\n",
    "\t# print(f' - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "\t# Early Stopping Condition\n",
    "\tif epoch_loss < best_loss:\n",
    "\t\tbest_loss = epoch_loss\n",
    "\t\tepochs_without_improvement = 0\n",
    "\t\tprint(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f}\")\n",
    "\telse:\n",
    "\t\tepochs_without_improvement += 1\n",
    "\t\tprint(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f}\", end=\"\\r\")\n",
    "\t\n",
    "\tif epochs_without_improvement >= early_stopping_patience:\n",
    "\t\tprint(f\"Early stopping triggered at epoch {epoch+1} due to no improvement.\")\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./models/{notebook}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7887\n",
      "F1 Score: 0.7762\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                    Others       0.99      0.99      0.99       200\n",
      "  Web Attack � Brute Force       0.64      0.37      0.47       200\n",
      "          Web Attack � XSS       0.58      0.79      0.67       200\n",
      "Web Attack � Sql Injection       0.95      1.00      0.98       200\n",
      "\n",
      "                  accuracy                           0.79       800\n",
      "                 macro avg       0.79      0.79      0.78       800\n",
      "              weighted avg       0.79      0.79      0.78       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_balanced.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test_balanced.values, dtype=torch.long).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "\toutputs = model(X_test_tensor)\n",
    "\t_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_tensor.cpu(), predicted.cpu()):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test_tensor.cpu(), predicted.cpu(), average=\"weighted\"):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test_tensor.cpu(), predicted.cpu(), target_names=attack_mapping))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
